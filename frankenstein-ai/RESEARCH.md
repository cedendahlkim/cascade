# üßü Frankenstein AI ‚Äî Forskningsdokumentation

**Projekt:** Flytande Intelligens med Hyperdimensionell Kognition och Aktiv Inferens
**Forskare:** Kim Cedendahl
**Start:** Februari 2026
**Status:** Aktiv prototyp, tr√§ningsfas

---

## 1. Bakgrund & Motivation

### Problemst√§llning

Nuvarande AI-system (LLM:er som GPT, Gemini, Claude) har fundamentala begr√§nsningar:

- **Ingen one-shot learning** ‚Äî kr√§ver massiv tr√§ningsdata
- **Inget adaptivt beslutsfattande** ‚Äî kan inte balansera exploration/exploitation
- **Inget biologiskt minne** ‚Äî ingen naturlig gl√∂mska eller konsolidering
- **Ingen m√∂nsterigenk√§nning utan backprop** ‚Äî allt kr√§ver gradient descent

### Hypotes

Genom att kombinera tre bio-inspirerade teknologier kan vi bygga en meta-l√§rande agent som:

1. L√§r sig m√∂nster med ett enda exempel (HDC)
2. Fattar beslut genom att minimera √∂verraskning (Active Inference)
3. Konsoliderar kunskap med biologisk gl√∂mskekurva (Ebbinghaus)

**Nyckelinsikt:** Systemet l√§r sig inte *svaren* ‚Äî det l√§r sig *hur man t√§nker om problem*.

---

## 2. Teoretisk Grund

### 2.1 Hyperdimensional Computing (HDC)

**K√§lla:** Kanerva (2009), "Hyperdimensional Computing: An Introduction to Computing in Distributed Representation with High-Dimensional Random Vectors"

- Representerar koncept som hypervektorer i ~4096 dimensioner
- Operationer: bundling (addition), binding (multiplikation), permutation
- **One-shot learning**: Ett enda exempel r√§cker f√∂r att l√§ra ett nytt koncept
- **Brustolerant**: Upp till 30% av vektorn kan korrumperas utan informationsf√∂rlust
- Kosinuslikhet f√∂r m√∂nstermatchning

**V√•r implementation:** `cognition.py` ‚Äî `NeuroSymbolicBridge`
- Random projection fr√•n feature-space (64D) till hyperspace (4096D)
- Konceptbibliotek med prototyp-hypervektorer
- Similarity threshold: 0.3 (l√§gre = fler nya koncept)

### 2.2 Active Inference (AIF)

**K√§lla:** Friston (2010), "The free-energy principle: a unified brain theory?"

- Agenten har en *generativ modell* av v√§rlden (A, B, C, D-matriser)
- Beslutsfattande genom att minimera **Expected Free Energy (EFE)**
- EFE = pragmatiskt v√§rde (exploitation) + epistemiskt v√§rde (exploration)
- Naturlig balans: utforskar n√§r os√§ker, utnyttjar n√§r s√§ker

**V√•r implementation:** `agency.py` ‚Äî `ActiveInferenceAgent`
- 8 observationstyper: solved_first, solved_retry, failed_logic, failed_syntax, failed_timeout, partial_solve, new_pattern, known_pattern
- 12 dolda tillst√•nd
- 4 handlingar (strategier): direct, with_hints, from_memory, step_by_step
- Exploration weight: startar 0.6, sjunker mot 0.15 vid framg√•ng

### 2.3 Ebbinghaus Minnesmodell

**K√§lla:** Ebbinghaus (1885), "√úber das Ged√§chtnis"

- Minnen har en *retention strength* som avtar exponentiellt: R = e^(-t/S)
- Varje recall f√∂rst√§rker minnet (√∂kar S)
- Svaga minnen gl√∂ms bort (garbage collection vid R < 0.05)
- Starka, ofta anv√§nda minnen blir permanenta

**V√•r implementation:** `memory.py` ‚Äî `EbbinghausMemory`
- ChromaDB-backend f√∂r persistent vektorlagring
- Metadata: retention, recall_count, last_recall, creation_time
- ShortTermBuffer (FIFO, 50 items) f√∂r omedelbar kontext

---

## 3. Systemarkitektur

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FRANKENSTEIN STACK                     ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇPERCEPTION‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ KOGNITION‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇAGENTSKAP ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ(Features)‚îÇ   ‚îÇ  (HDC)   ‚îÇ   ‚îÇ  (AIF)   ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ       ‚îÇ              ‚îÇ              ‚îÇ                    ‚îÇ
‚îÇ       ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ       ‚îÇ         ‚îÇ Koncept ‚îÇ    ‚îÇStrategi ‚îÇ              ‚îÇ
‚îÇ       ‚îÇ         ‚îÇBibliotek‚îÇ    ‚îÇ  Val    ‚îÇ              ‚îÇ
‚îÇ       ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ       ‚îÇ                             ‚îÇ                    ‚îÇ
‚îÇ       ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ       ‚îÇ    ‚îÇ         LLM (Gemini)          ‚îÇ            ‚îÇ
‚îÇ       ‚îÇ    ‚îÇ    Kodgenerering med vald     ‚îÇ            ‚îÇ
‚îÇ       ‚îÇ    ‚îÇ    strategi och kontext       ‚îÇ            ‚îÇ
‚îÇ       ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ       ‚îÇ                 ‚îÇ                               ‚îÇ
‚îÇ       ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ       ‚îÇ    ‚îÇ       UTV√ÑRDERING            ‚îÇ            ‚îÇ
‚îÇ       ‚îÇ    ‚îÇ  K√∂r kod mot testfall        ‚îÇ            ‚îÇ
‚îÇ       ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îÇ       ‚îÇ                 ‚îÇ                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ            MINNE (Ebbinghaus)           ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ  Lagra l√∂sning ‚Üí F√∂rst√§rk/Gl√∂m         ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Datafl√∂de per uppgift

1. **Perception**: Uppgiftstext ‚Üí 64D feature-vektor (keyword-boosting, TF-IDF-liknande)
2. **Kognition**: Feature ‚Üí 4096D hypervektor ‚Üí Kosinusmatchning mot konceptbibliotek
3. **Agentskap**: Observation (ny/k√§nd/misslyckad) ‚Üí AIF ‚Üí Strategi (direct/hints/memory/step)
4. **Generering**: Strategi + uppgift + ev. minnen ‚Üí LLM-prompt ‚Üí Kod
5. **Utv√§rdering**: Kod k√∂rs i sandbox mot testfall ‚Üí Score (0.0‚Äì1.0)
6. **Inl√§rning**: HDC l√§r m√∂nster, AIF uppdaterar preferenser, Ebbinghaus lagrar/f√∂rst√§rker

---

## 4. Tr√§ningsdom√§n: Kodgenerering

### Varf√∂r kodgenerering?

- **Objektivt m√§tbart**: Testfall ger exakt score (0% eller 100%)
- **Skalbar sv√•righet**: 8 niv√•er fr√•n aritmetik till dynamisk programmering
- **Rik m√∂nsterrymd**: 17+ uppgiftstyper med parametrisk variation
- **Snabb feedback-loop**: Sekunder per uppgift, inte timmar

### Sv√•righetsniv√•er

| Niv√• | Dom√§n | Uppgiftstyper | Exempel |
|------|-------|---------------|---------|
| 1 | Aritmetik | Grundl√§ggande I/O, ber√§kningar | Summa, area, temperatur |
| 2 | Kontrollfl√∂de | Villkor, loopar, m√∂nster | FizzBuzz, trianglar, nedr√§kning |
| 3 | Str√§ngar & Listor | Manipulation, talteori | Palindrom, vokaler, fakultet |
| 4 | Algoritmer | Dict, rekursion, matriser | Primtal, bin√§rs√∂kning, ordfrekvens |
| 5 | Sortering & Str√§ngar | Sorteringsalgoritmer, chiffer | Bubble sort, Caesar, anagram |
| 6 | Datastrukturer | Stack, k√∂, l√§nkad lista | Balanserade parenteser, min-stack |
| 7 | Funktionell & Grafer | Map/filter, BFS/DFS | Flatten, zip, sammanh√§ngande komponenter |
| 8 | DP & Kombinatorik | Dynamisk programmering | Kadane, coin change, LIS, permutationer |

### Adaptiv Sv√•righet

- Kl√§ttrar vid ‚â•75% l√∂sningsgrad (‚â•70% f√∂r niv√• 5+)
- Backar vid <25% l√∂sningsgrad
- Utv√§rderar senaste 15 uppgifter p√• nuvarande niv√•

---

## 5. Experimentresultat

### Baseline ‚Äî Session 1 (v2, 2026-02-10)

| Metrik | V√§rde |
|--------|-------|
| Uppgifter | 138 |
| L√∂sta | 105 (76%) |
| Tid | 8 minuter |
| Max niv√• n√•dd | 8 |
| HDC Koncept | 49 |
| AIF Exploration | 0.29 (start: 0.60) |
| AIF Surprise | 2.08 |
| Ebbinghaus aktiva | 25 av 111 lagrade |
| B√§sta streak | 12 |
| Skills | 58 |

#### Per niv√•

| Niv√• | L√∂sta/F√∂rs√∂kta | L√∂sningsgrad |
|------|----------------|--------------|
| 1 | 4/5 | 80% |
| 2 | 12/16 | 75% |
| 3 | 19/26 | 73% |
| 4 | 33/45 | 73% |
| 5 | 37/46 | 80% |
| 6 | 0/0 | ‚Äî |
| 7 | 0/0 | ‚Äî |
| 8 | 0/0 | ‚Äî |

### Observationer

1. **Exploration sjunker**: 0.60 ‚Üí 0.29 ‚Äî systemet l√§r sig vilka strategier som fungerar
2. **Minneskonsolidering fungerar**: 86 av 111 minnen gl√∂mda ‚Äî svaga l√∂sningar rensas
3. **Niv√• 5 √∂vertr√§ffar niv√• 1-4**: 80% vs 73-80% ‚Äî m√∂jligen b√§ttre prompt-engineering f√∂r avancerade uppgifter
4. **Niv√• 6-8 ej n√•dda i fas 2**: Adaptiv difficulty hoppade direkt till 8 men sessionen avslutades

---

## 6. K√§nda Begr√§nsningar

1. **Perception √§r enkel**: Keyword-boosting ist√§llet f√∂r riktig embedding ‚Äî missar semantiska nyanser
2. **Ingen spaced repetition √§nnu**: Sv√•ra uppgifter √•terbes√∂ks inte systematiskt
3. **LLM-beroende**: Frankenstein styr processen men Gemini g√∂r det tunga arbetet
4. **Ingen cross-domain transfer**: Tr√§nad p√• kod, kan inte direkt appliceras p√• andra dom√§ner
5. **Sandbox-begr√§nsningar**: Timeout 10s, ingen n√§tverks√•tkomst, begr√§nsad minnesanv√§ndning

---

## 7. N√§sta Steg

Se `ROADMAP.md` f√∂r detaljerad forskningsplan.

---

## 8. Referenser

1. Kanerva, P. (2009). Hyperdimensional Computing: An Introduction. *Cognitive Computation*.
2. Friston, K. (2010). The free-energy principle: a unified brain theory? *Nature Reviews Neuroscience*.
3. Ebbinghaus, H. (1885). √úber das Ged√§chtnis.
4. Hasani, R. et al. (2021). Liquid Time-constant Networks. *AAAI*.
5. Da Costa, L. et al. (2020). Active Inference on Discrete State-Spaces. *Journal of Mathematical Psychology*.
6. Kleyko, D. et al. (2022). A Survey on Hyperdimensional Computing. *ACM Computing Surveys*.
