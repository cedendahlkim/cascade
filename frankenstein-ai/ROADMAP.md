# üó∫Ô∏è Frankenstein AI ‚Äî Forskningsplan & Roadmap

**Version:** 1.0
**Senast uppdaterad:** 2026-02-10

---

## √ñvergripande M√•l

Bygga en **generell meta-l√§rande agent** som kan appliceras p√• godtyckliga dom√§ner, med kodgenerering som f√∂rsta tr√§ningsdom√§n.

---

## Fas 1: Grundl√§ggande Stack ‚úÖ (Klar)

**M√•l:** Bevisa att HDC + AIF + Ebbinghaus kan samverka

- [x] HDC kognition med one-shot learning
- [x] Active Inference med EFE-minimering
- [x] Ebbinghaus minne med gl√∂mskekurva
- [x] Integration i FrankensteinCodeAgent
- [x] Grundl√§ggande tr√§ningsloop (continuous_train.py)
- [x] Dashboard i Cascade Remote (FrankensteinView)

**Resultat:** 76% l√∂sningsgrad, 49 koncept, exploration 0.60‚Üí0.29

---

## Fas 2: Ut√∂kad Tr√§ning ‚úÖ (Klar)

**M√•l:** Bredda uppgiftsrymden och f√∂rb√§ttra inl√§rningen

- [x] 8 sv√•righetsniv√•er (var 5)
- [x] 17 uppgiftsgeneratorer (sortering, datastrukturer, grafer, DP, kombinatorik)
- [x] 8 AIF-observationer (partial, syntax, timeout)
- [x] Felklassificering (syntax/logic/timeout/runtime)
- [x] Strategi-framg√•ngssp√•rning
- [x] B√§ttre prompt-engineering (alla testfall, feltyp-specifik retry)
- [x] Smartare adaptive difficulty (niv√•specifik utv√§rdering)

**Resultat:** Baseline etablerad, redo f√∂r l√§ngre tr√§ningsk√∂rningar

---

## Fas 3: Djupare Inl√§rning üîÑ (P√•g√•ende)

**M√•l:** F√∂rb√§ttra inl√§rningskvaliteten och minnesanv√§ndningen

### 3.1 Spaced Repetition
- [ ] √Öterbes√∂k misslyckade uppgiftstyper med √∂kande intervall
- [ ] Prioritera uppgifter d√§r l√∂sningsgraden √§r 30-70% (inl√§rningszonen)
- [ ] Ebbinghaus-driven schemal√§ggning av repetitioner

### 3.2 Hierarkisk HDC
- [ ] Sub-koncept: "sorting" ‚Üí "bubble_sort", "merge_sort", "insertion_sort"
- [ ] Koncepthierarki med similarity threshold decay
- [ ] Transfer learning mellan liknande koncept

### 3.3 F√∂rb√§ttrad Perception
- [ ] Sentence embeddings ist√§llet f√∂r keyword-boosting
- [ ] Kontextuella features (sv√•righetsgrad, uppgiftstyp, kodl√§ngd)
- [ ] Temporal features (tid p√• dygnet, session-position)

### 3.4 Multi-LLM Routing
- [ ] AIF v√§ljer inte bara strategi utan √§ven LLM (Gemini vs Grok vs lokal)
- [ ] Kostnads-medveten routing (billigare modell f√∂r enkla uppgifter)
- [ ] Fallback-kedja vid API-fel

**Milstolpe:** ‚â•85% l√∂sningsgrad p√• niv√• 1-5, ‚â•60% p√• niv√• 6-8

---

## Fas 4: Generalisering üìã (Planerad)

**M√•l:** Applicera Frankenstein-stacken p√• andra dom√§ner

### 4.1 Unity-utveckling
- [ ] Uppgifter: Skapa GameObjects, skript, prefabs via MCP
- [ ] HDC l√§r sig Unity-m√∂nster (Singleton, Observer, State Machine)
- [ ] AIF styr vilka MCP-verktyg som anv√§nds

### 4.2 Projektplanering
- [ ] Uppgifter: Bryt ner features till tasks
- [ ] HDC k√§nner igen projekttyper
- [ ] Ebbinghaus minns vilka estimat som var korrekta

### 4.3 Fels√∂kning
- [ ] Uppgifter: Diagnostisera och fixa buggar
- [ ] HDC matchar felmeddelanden mot k√§nda m√∂nster
- [ ] AIF v√§ljer debug-strategi (logga, isolera, reproducera)

**Milstolpe:** Frankenstein kan styra minst 2 dom√§ner med delad kunskapsbas

---

## Fas 5: Sj√§lvf√∂rb√§ttring üîÆ (Framtid)

**M√•l:** Systemet f√∂rb√§ttrar sig sj√§lv

### 5.1 Meta-meta-learning
- [ ] Frankenstein analyserar sin egen inl√§rningskurva
- [ ] Justerar HDC-dimensioner, AIF-parametrar, Ebbinghaus-thresholds automatiskt

### 5.2 Kunskapsdelning
- [ ] Flera Frankenstein-instanser delar koncept via federation
- [ ] Distribuerad HDC: koncept synkas mellan agenter

### 5.3 F√∂rklarbarhet
- [ ] Varje beslut kan sp√•ras: "Jag valde X f√∂r att Y"
- [ ] Konceptvisualisering: vilka m√∂nster har systemet l√§rt sig?
- [ ] Confidence calibration: √§r systemet r√§tt kalibrerat?

**Milstolpe:** Systemet kan f√∂rklara varf√∂r det valde en viss strategi

---

## M√§tplan

### Nyckelmetrik

| Metrik | Beskrivning | M√•l |
|--------|-------------|-----|
| **Solve Rate** | Andel l√∂sta uppgifter | ‚â•85% (niv√• 1-5) |
| **First-Try Rate** | L√∂st utan retry | ‚â•60% |
| **Exploration Decay** | Hur snabbt AIF konvergerar | 0.60‚Üí0.15 inom 500 uppgifter |
| **Concept Efficiency** | Uppgifter per nytt koncept | ‚â§5 |
| **Memory Retention** | Andel aktiva minnen | 20-40% (resten gl√∂mda = bra) |
| **Strategy Convergence** | B√§sta strategi per uppgiftstyp | Tydlig preferens efter 100 uppgifter |
| **Level Progression** | Tid till niv√• 8 | <30 minuter |
| **Cross-Domain Transfer** | Prestanda i ny dom√§n med befintlig kunskap | >50% dag 1 |

### Datainsamling

- `progress.json` ‚Äî L√∂pande statistik per session
- `training.log` ‚Äî Detaljerad logg per uppgift
- `solutions/` ‚Äî Alla genererade l√∂sningar
- Dashboard ‚Äî Realtidsvisualisering i Cascade Remote

---

## Risker & Mitigering

| Risk | Sannolikhet | Konsekvens | Mitigering |
|------|-------------|------------|------------|
| LLM API-kostnader | H√∂g | Medel | Gemini Flash (gratis tier), lokal fallback |
| Overfitting till koddom√§nen | Medel | H√∂g | Abstrakt arkitektur, dom√§n-agnostisk HDC |
| HDC skalbarhet | L√•g | H√∂g | Dimensionsreduktion, hierarkisk HDC |
| AIF konvergerar f√∂r snabbt | Medel | Medel | Minimum exploration weight (0.15) |
| Ebbinghaus gl√∂mmer f√∂r mycket | L√•g | Medel | Justerbar decay threshold |
